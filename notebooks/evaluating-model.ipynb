{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/khabaronline-recrawl.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device=torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def calculate_similarity(labels, texts, label_embeddings=None, text_embeddings=None):\n",
    "    if label_embeddings is None:\n",
    "        label_embeddings = model.encode(labels,show_progress_bar=True)\n",
    "    if text_embeddings is None:\n",
    "        text_embeddings = model.encode(texts,True)\n",
    "    scores = {}\n",
    "    # return a dict with each label and its probability score\n",
    "    # Something like this: [{'label1': 0.8, 'label2': 0.2, ...}, ...]\n",
    "    with tqdm(total=len(texts), desc=\"Calculating similarity\") as pbar:\n",
    "        for i, text in enumerate(texts):\n",
    "            text_embedding = text_embeddings[i].reshape(1, -1)\n",
    "            similarity = cosine_similarity(text_embedding, label_embeddings)\n",
    "            scores[text] = {}\n",
    "            for j, label in enumerate(labels):\n",
    "                scores[text][label] = similarity[0][j]\n",
    "            pbar.update(1)\n",
    "    return scores\n",
    "\n",
    "def classify(labels, texts, label_embeddings=None, text_embeddings=None):\n",
    "    scores = calculate_similarity(labels, texts, label_embeddings, text_embeddings)\n",
    "    highest_labels = []\n",
    "    for text in texts:\n",
    "        highest_label = max(scores[text], key=scores[text].get)\n",
    "        highest_labels.append(highest_label)\n",
    "    return highest_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = ['سیاسی','اقتصادی','اجتماعی']\n",
    "# filter service column\n",
    "df = df[df['service'].isin(['اخبار سیاسی','اخبار اقتصادی','اخبار اجتماعی'])]\n",
    "# remove row if body column doesn't have persian characters\n",
    "df = df[df['abstract'].str.contains(r'[\\u0600-\\u06FF]+')]\n",
    "# Get rid of a certain term from all of the values of service column\n",
    "df = df.replace({'service': {'اخبار ': ''}}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcbc86fbf8a492ab28d9c7bbc14cc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b33d22e7654feab9b64039d5d9d496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d8b4538c5c4961910ec1ae9d58472a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['سیاسی','اقتصادی','اجتماعی']\n",
    "labels_sentence = ['خبری درباره سیاست','خبری درباره اقتصاد','خبری درباره اجتماع']\n",
    "labels_embeddings = model.encode(labels, show_progress_bar=True)\n",
    "labels_sentence_embeddings = model.encode(labels_sentence, show_progress_bar=True)\n",
    "body_embeddings = model.encode(df['body'].values, show_progress_bar=True)\n",
    "df['service_category'] = classify(labels, df['body'].values, labels_embeddings, body_embeddings)\n",
    "df['service_category_sent'] = classify(labels_sentence, df['body'].values, labels_sentence_embeddings, body_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_map = {'خبری درباره سیاست': 'سیاسی', 'خبری درباره اقتصاد': 'اقتصادی', 'خبری درباره اجتماع': 'اجتماعی'}\n",
    "df['service_category_sent'] = df['service_category_sent'].map(service_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       سیاسی       0.35      0.58      0.44      2343\n",
      "     اقتصادی       0.82      0.83      0.83      4462\n",
      "     اجتماعی       0.81      0.63      0.71      6943\n",
      "\n",
      "    accuracy                           0.69     13748\n",
      "   macro avg       0.66      0.68      0.66     13748\n",
      "weighted avg       0.74      0.69      0.70     13748\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       سیاسی       0.44      0.31      0.37      2343\n",
      "     اقتصادی       0.87      0.78      0.82      4462\n",
      "     اجتماعی       0.74      0.86      0.79      6943\n",
      "\n",
      "    accuracy                           0.74     13748\n",
      "   macro avg       0.68      0.65      0.66     13748\n",
      "weighted avg       0.73      0.74      0.73     13748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix plot\n",
    "y_test = df['service']\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, df['service_category_sent'], target_names=labels))\n",
    "print(classification_report(y_test, df['service_category'], target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
